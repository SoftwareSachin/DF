"""
Deep Fake Detection System - Streamlit Web Application
Production-grade deep fake detection using MesoNet and Xception neural networks.
"""
import streamlit as st
import numpy as np
import cv2
import tempfile
import os
from typing import Dict, List, Tuple, Optional
import time
import json
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd

# Import our detection modules
from models.mesonet import MesoNet, MesoNet4
from models.xception_detector import XceptionDetector
from detectors.face_detector import FaceDetector
from detectors.temporal_analyzer import TemporalAnalyzer
from detectors.frequency_analyzer import FrequencyAnalyzer
from utils.video_processor import VideoProcessor
from utils.image_processor import ImageProcessor
from utils.confidence_scorer import ConfidenceScorer
from utils.timeline_visualizer import TimelineVisualizer
from config import *

# Page configuration
st.set_page_config(
    page_title="Deep Fake Detection System",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #667eea;
        margin: 0.5rem 0;
    }
    .detection-result {
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    .real-result {
        background: #d4edda;
        border: 1px solid #c3e6cb;
    }
    .fake-result {
        background: #f8d7da;
        border: 1px solid #f5c6cb;
    }
    .analysis-section {
        background: #ffffff;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

class DeepFakeDetectionApp:
    """Main application class for the deep fake detection system."""
    
    def __init__(self):
        self.initialize_models()
        self.initialize_processors()
    
    def initialize_models(self):
        """Initialize AI models with loading indicators."""
        with st.spinner("Initializing AI models..."):
            try:
                # Initialize MesoNet models
                self.mesonet = MesoNet(input_size=MESONET_INPUT_SIZE)
                self.mesonet.load_weights(MESONET_WEIGHTS_PATH)
                
                self.mesonet4 = MesoNet4(input_size=MESONET_INPUT_SIZE)
                
                # Initialize Xception detector
                self.xception = XceptionDetector(input_size=XCEPTION_INPUT_SIZE)
                self.xception.load_weights(XCEPTION_WEIGHTS_PATH)
                
                # Initialize detectors
                self.face_detector = FaceDetector()
                self.temporal_analyzer = TemporalAnalyzer()
                self.frequency_analyzer = FrequencyAnalyzer()
                
                # Initialize confidence scorer
                self.confidence_scorer = ConfidenceScorer()
                
                # Initialize timeline visualizer
                self.timeline_visualizer = TimelineVisualizer()
                
                st.success("‚úÖ All AI models initialized successfully!")
                
            except Exception as e:
                st.error(f"‚ùå Error initializing models: {str(e)}")
                st.warning("Some models may not be available. The system will work with reduced functionality.")
    
    def initialize_processors(self):
        """Initialize image and video processors."""
        self.image_processor = ImageProcessor()
        self.video_processor = VideoProcessor(
            max_frames=MAX_FRAMES_TO_ANALYZE,
            frame_skip=FRAME_SKIP_INTERVAL
        )
    
    def render_header(self):
        """Render the application header."""
        st.markdown("""
        <div class="main-header">
            <h1 style="color: white; margin: 0;">üîç Deep Fake Detection System</h1>
            <p style="color: white; margin: 0; opacity: 0.9;">
                Production-grade AI-powered authenticity verification for images and videos
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    def render_sidebar(self):
        """Render the sidebar with configuration options."""
        st.sidebar.title("‚öôÔ∏è Detection Settings")
        
        # Model selection
        st.sidebar.subheader("Model Configuration")
        use_mesonet = st.sidebar.checkbox("Enable MesoNet Detection", value=True)
        use_xception = st.sidebar.checkbox("Enable Xception Detection", value=True)
        use_face_analysis = st.sidebar.checkbox("Enable Facial Analysis", value=True)
        use_frequency_analysis = st.sidebar.checkbox("Enable Frequency Analysis", value=True)
        
        # Detection thresholds
        st.sidebar.subheader("Detection Thresholds")
        deepfake_threshold = st.sidebar.slider(
            "Deep Fake Threshold",
            min_value=0.0,
            max_value=1.0,
            value=DEEPFAKE_THRESHOLD,
            step=0.05,
            help="Threshold for classifying as deep fake"
        )
        
        confidence_threshold = st.sidebar.slider(
            "Confidence Threshold",
            min_value=0.0,
            max_value=1.0,
            value=CONFIDENCE_THRESHOLD,
            step=0.05,
            help="Minimum confidence for reliable detection"
        )
        
        # Video analysis settings
        st.sidebar.subheader("Video Analysis Settings")
        max_frames = st.sidebar.number_input(
            "Max Frames to Analyze",
            min_value=5,
            max_value=100,
            value=MAX_FRAMES_TO_ANALYZE,
            help="Maximum number of frames to extract and analyze"
        )
        
        frame_skip = st.sidebar.number_input(
            "Frame Skip Interval",
            min_value=1,
            max_value=30,
            value=FRAME_SKIP_INTERVAL,
            help="Number of frames to skip between analyses"
        )
        
        return {
            'use_mesonet': use_mesonet,
            'use_xception': use_xception,
            'use_face_analysis': use_face_analysis,
            'use_frequency_analysis': use_frequency_analysis,
            'deepfake_threshold': deepfake_threshold,
            'confidence_threshold': confidence_threshold,
            'max_frames': max_frames,
            'frame_skip': frame_skip
        }
    
    def process_image(self, uploaded_file, settings: Dict) -> Dict:
        """Process uploaded image for deep fake detection."""
        try:
            # Load image
            image_bytes = uploaded_file.read()
            image = self.image_processor.load_image_from_bytes(image_bytes)
            
            # Extract metadata
            metadata = self.image_processor.extract_metadata(image_bytes)
            
            # Analyze image properties
            properties = self.image_processor.analyze_image_properties(image)
            
            # Detect faces
            faces = self.face_detector.detect_faces(image)
            
            if not faces:
                return {
                    'error': 'No faces detected in the image',
                    'metadata': metadata,
                    'properties': properties
                }
            
            # Use the largest face for analysis
            main_face = max(faces, key=lambda f: f[2] * f[3])
            
            results = {
                'image_shape': image.shape,
                'faces_detected': len(faces),
                'main_face_bbox': main_face,
                'metadata': metadata,
                'properties': properties,
                'detections': {}
            }
            
            # MesoNet detection
            if settings['use_mesonet']:
                try:
                    x, y, w, h = main_face
                    face_region = image[y:y+h, x:x+w]
                    meso_prob, meso_details = self.mesonet.predict(face_region)
                    results['detections']['mesonet'] = {
                        'probability': meso_prob,
                        'details': meso_details
                    }
                except Exception as e:
                    results['detections']['mesonet'] = {'error': str(e)}
            
            # Xception detection
            if settings['use_xception']:
                try:
                    x, y, w, h = main_face
                    face_region = image[y:y+h, x:x+w]
                    xception_prob, xception_details = self.xception.predict(face_region)
                    results['detections']['xception'] = {
                        'probability': xception_prob,
                        'details': xception_details
                    }
                except Exception as e:
                    results['detections']['xception'] = {'error': str(e)}
            
            # Facial analysis
            if settings['use_face_analysis']:
                try:
                    landmarks = self.face_detector.extract_landmarks(image, main_face)
                    if landmarks is not None:
                        facial_analysis = self.face_detector.analyze_facial_geometry(landmarks)
                        face_quality = self.face_detector.analyze_face_quality(image, main_face)
                        results['detections']['facial_analysis'] = {
                            'geometry': facial_analysis,
                            'quality': face_quality,
                            'landmarks_count': len(landmarks)
                        }
                except Exception as e:
                    results['detections']['facial_analysis'] = {'error': str(e)}
            
            # Frequency analysis
            if settings['use_frequency_analysis']:
                try:
                    freq_analysis = self.frequency_analyzer.analyze_frequency_domain(image, main_face)
                    results['detections']['frequency_analysis'] = freq_analysis
                except Exception as e:
                    results['detections']['frequency_analysis'] = {'error': str(e)}
            
            # Calculate final confidence score
            confidence_result = self.confidence_scorer.calculate_confidence(
                results['detections'],
                settings['deepfake_threshold']
            )
            results['confidence_score'] = confidence_result
            
            return results
            
        except Exception as e:
            return {'error': f'Error processing image: {str(e)}'}
    
    def process_video(self, uploaded_file, settings: Dict) -> Dict:
        """Process uploaded video for deep fake detection."""
        try:
            # Save uploaded file temporarily
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_file_path = tmp_file.name
            
            # Extract frames
            frames, video_metadata = self.video_processor.extract_frames(tmp_file_path)
            
            # Clean up temporary file
            os.unlink(tmp_file_path)
            
            # Detect faces in frames
            face_bboxes = []
            valid_frames = []
            
            for frame in frames:
                faces = self.face_detector.detect_faces(frame)
                if faces:
                    # Use the largest face
                    main_face = max(faces, key=lambda f: f[2] * f[3])
                    face_bboxes.append(main_face)
                    valid_frames.append(frame)
            
            if not valid_frames:
                return {
                    'error': 'No faces detected in video frames',
                    'video_metadata': video_metadata,
                    'total_frames': len(frames)
                }
            
            results = {
                'video_metadata': video_metadata,
                'total_frames': len(frames),
                'frames_with_faces': len(valid_frames),
                'face_bboxes': face_bboxes,
                'detections': {}
            }
            
            # Analyze representative frames
            frame_results = []
            analysis_frames = valid_frames[::max(1, len(valid_frames)//5)]  # Analyze up to 5 frames
            
            for i, frame in enumerate(analysis_frames):
                frame_result = {'frame_index': i}
                
                # Get corresponding face bbox
                face_bbox = face_bboxes[i * max(1, len(valid_frames)//5)]
                x, y, w, h = face_bbox
                face_region = frame[y:y+h, x:x+w]
                
                # MesoNet detection
                if settings['use_mesonet']:
                    try:
                        meso_prob, meso_details = self.mesonet.predict(face_region)
                        frame_result['mesonet'] = {
                            'probability': meso_prob,
                            'details': meso_details
                        }
                    except Exception as e:
                        frame_result['mesonet'] = {'error': str(e)}
                
                # Xception detection
                if settings['use_xception']:
                    try:
                        xception_prob, xception_details = self.xception.predict(face_region)
                        frame_result['xception'] = {
                            'probability': xception_prob,
                            'details': xception_details
                        }
                    except Exception as e:
                        frame_result['xception'] = {'error': str(e)}
                
                frame_results.append(frame_result)
            
            results['frame_analysis'] = frame_results
            
            # Temporal analysis
            if len(valid_frames) > 1:
                try:
                    temporal_analysis = self.temporal_analyzer.analyze_temporal_consistency(
                        valid_frames, face_bboxes[:len(valid_frames)]
                    )
                    results['detections']['temporal_analysis'] = temporal_analysis
                except Exception as e:
                    results['detections']['temporal_analysis'] = {'error': str(e)}
            
            # Calculate overall confidence
            # Aggregate frame results for final scoring
            aggregated_detections = {}
            
            # Average MesoNet scores
            meso_scores = [fr.get('mesonet', {}).get('probability') for fr in frame_results 
                          if 'mesonet' in fr and 'probability' in fr['mesonet']]
            if meso_scores:
                aggregated_detections['mesonet'] = {
                    'probability': np.mean(meso_scores),
                    'frame_scores': meso_scores
                }
            
            # Average Xception scores
            xception_scores = [fr.get('xception', {}).get('probability') for fr in frame_results 
                             if 'xception' in fr and 'probability' in fr['xception']]
            if xception_scores:
                aggregated_detections['xception'] = {
                    'probability': np.mean(xception_scores),
                    'frame_scores': xception_scores
                }
            
            # Include temporal analysis
            if 'temporal_analysis' in results['detections']:
                aggregated_detections['temporal_analysis'] = results['detections']['temporal_analysis']
            
            confidence_result = self.confidence_scorer.calculate_confidence(
                aggregated_detections,
                settings['deepfake_threshold']
            )
            results['confidence_score'] = confidence_result
            
            return results
            
        except Exception as e:
            return {'error': f'Error processing video: {str(e)}'}
    
    def render_results(self, results: Dict, file_type: str):
        """Render detection results."""
        if 'error' in results:
            st.error(f"‚ùå {results['error']}")
            return
        
        # Main detection result
        confidence_score = results.get('confidence_score', {})
        final_confidence = confidence_score.get('final_confidence', 0.0)
        is_deepfake = confidence_score.get('is_deepfake', False)
        
        # Display main result
        result_class = "fake-result" if is_deepfake else "real-result"
        result_text = "üö® DEEP FAKE DETECTED" if is_deepfake else "‚úÖ LIKELY AUTHENTIC"
        confidence_text = f"Confidence: {final_confidence:.1%}"
        
        st.markdown(f"""
        <div class="detection-result {result_class}">
            <h2>{result_text}</h2>
            <h3>{confidence_text}</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # Create tabs for different analyses
        if file_type == "image":
            tabs = st.tabs(["üìä Overview", "ü§ñ AI Detection", "üë§ Facial Analysis", "üì° Frequency Analysis", "üìã Metadata"])
        else:
            tabs = st.tabs(["üìä Overview", "ü§ñ AI Detection", "üé¨ Temporal Analysis", "üìà Timeline Analysis", "üìã Video Info"])
        
        # Overview tab
        with tabs[0]:
            self.render_overview_tab(results, confidence_score)
        
        # AI Detection tab
        with tabs[1]:
            self.render_ai_detection_tab(results)
        
        # Type-specific tabs
        if file_type == "image":
            with tabs[2]:
                self.render_facial_analysis_tab(results)
            
            with tabs[3]:
                self.render_frequency_analysis_tab(results)
            
            with tabs[4]:
                self.render_metadata_tab(results)
        else:
            with tabs[2]:
                self.render_temporal_analysis_tab(results)
            
            with tabs[3]:
                self.render_timeline_analysis_tab(results)
            
            with tabs[4]:
                self.render_video_info_tab(results)
    
    def render_overview_tab(self, results: Dict, confidence_score: Dict):
        """Render the overview tab."""
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "Final Confidence",
                f"{confidence_score.get('final_confidence', 0):.1%}",
                delta=None
            )
        
        with col2:
            detection_count = len([k for k, v in results.get('detections', {}).items() 
                                 if 'error' not in v])
            st.metric("Active Detectors", detection_count)
        
        with col3:
            faces_detected = results.get('faces_detected', results.get('frames_with_faces', 0))
            st.metric("Faces Detected", faces_detected)
        
        # Confidence breakdown
        st.subheader("üìà Detection Breakdown")
        
        breakdown = confidence_score.get('breakdown', {})
        if breakdown:
            breakdown_df = pd.DataFrame([
                {'Detector': k.replace('_', ' ').title(), 
                 'Score': v.get('score', 0), 
                 'Weight': v.get('weight', 0),
                 'Contribution': v.get('weighted_score', 0)}
                for k, v in breakdown.items()
            ])
            
            fig = px.bar(
                breakdown_df, 
                x='Detector', 
                y='Contribution',
                title="Detection Contribution by Method",
                color='Contribution',
                color_continuous_scale='RdYlBu_r'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    def render_ai_detection_tab(self, results: Dict):
        """Render AI detection results."""
        detections = results.get('detections', {})
        
        # MesoNet Results
        if 'mesonet' in detections:
            st.subheader("üß† MesoNet Detection")
            meso_data = detections['mesonet']
            
            if 'error' in meso_data:
                st.error(f"MesoNet Error: {meso_data['error']}")
            else:
                prob = meso_data.get('probability', 0)
                st.metric("Deep Fake Probability", f"{prob:.1%}")
                
                # Feature analysis
                if 'details' in meso_data:
                    details = meso_data['details']
                    if 'feature_maps' in details:
                        st.write("**Feature Map Analysis:**")
                        feature_df = pd.DataFrame(details['feature_maps']).T
                        st.dataframe(feature_df)
        
        # Xception Results
        if 'xception' in detections:
            st.subheader("üîç Xception Detection")
            xception_data = detections['xception']
            
            if 'error' in xception_data:
                st.error(f"Xception Error: {xception_data['error']}")
            else:
                prob = xception_data.get('probability', 0)
                st.metric("Deep Fake Probability", f"{prob:.1%}")
                
                # Feature analysis
                if 'details' in xception_data:
                    details = xception_data['details']
                    if 'feature_analysis' in details:
                        st.write("**Feature Analysis:**")
                        feature_analysis = details['feature_analysis']
                        for key, value in feature_analysis.items():
                            st.write(f"- **{key.replace('_', ' ').title()}:** {value:.4f}")
    
    def render_facial_analysis_tab(self, results: Dict):
        """Render facial analysis results."""
        detections = results.get('detections', {})
        
        if 'facial_analysis' in detections:
            facial_data = detections['facial_analysis']
            
            if 'error' in facial_data:
                st.error(f"Facial Analysis Error: {facial_data['error']}")
            else:
                # Geometry analysis
                if 'geometry' in facial_data:
                    st.subheader("üìê Geometric Analysis")
                    geometry = facial_data['geometry']
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if 'symmetry_score' in geometry:
                            st.metric("Facial Symmetry", f"{geometry['symmetry_score']:.3f}")
                        
                        if 'proportions' in geometry:
                            st.write("**Facial Proportions:**")
                            for key, value in geometry['proportions'].items():
                                st.write(f"- {key.replace('_', ' ').title()}: {value:.3f}")
                    
                    with col2:
                        if 'anomalies' in geometry:
                            st.write("**Detected Anomalies:**")
                            anomalies = geometry['anomalies']
                            if anomalies:
                                for anomaly in anomalies:
                                    st.warning(f"‚ö†Ô∏è {anomaly.replace('_', ' ').title()}")
                            else:
                                st.success("‚úÖ No geometric anomalies detected")
                
                # Quality analysis
                if 'quality' in facial_data:
                    st.subheader("üéØ Face Quality Metrics")
                    quality = facial_data['quality']
                    
                    quality_cols = st.columns(4)
                    metrics = ['sharpness', 'contrast', 'brightness', 'edge_density']
                    
                    for i, metric in enumerate(metrics):
                        if metric in quality:
                            with quality_cols[i]:
                                st.metric(
                                    metric.replace('_', ' ').title(),
                                    f"{quality[metric]:.2f}"
                                )
        else:
            st.info("Facial analysis not performed or no faces detected.")
    
    def render_frequency_analysis_tab(self, results: Dict):
        """Render frequency analysis results."""
        detections = results.get('detections', {})
        
        if 'frequency_analysis' in detections:
            freq_data = detections['frequency_analysis']
            
            if 'error' in freq_data:
                st.error(f"Frequency Analysis Error: {freq_data['error']}")
            else:
                # DCT Analysis
                if 'dct_analysis' in freq_data:
                    st.subheader("üìä DCT Block Analysis")
                    dct_data = freq_data['dct_analysis']
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if 'quantization_artifacts' in dct_data:
                            st.metric("Quantization Artifacts", dct_data['quantization_artifacts'])
                    
                    with col2:
                        if 'dc_variance' in dct_data:
                            st.metric("DC Coefficient Variance", f"{dct_data['dc_variance']:.2f}")
                    
                    with col3:
                        if 'dc_range' in dct_data:
                            st.metric("DC Range", f"{dct_data['dc_range']:.2f}")
                
                # FFT Analysis
                if 'fft_analysis' in freq_data:
                    st.subheader("üåä FFT Spectrum Analysis")
                    fft_data = freq_data['fft_analysis']
                    
                    metrics_cols = st.columns(2)
                    
                    with metrics_cols[0]:
                        for key in ['spectral_centroid', 'spectral_rolloff']:
                            if key in fft_data:
                                st.metric(
                                    key.replace('_', ' ').title(),
                                    f"{fft_data[key]:.4f}"
                                )
                    
                    with metrics_cols[1]:
                        for key in ['spectral_flatness', 'spectral_energy']:
                            if key in fft_data:
                                st.metric(
                                    key.replace('_', ' ').title(),
                                    f"{fft_data[key]:.4e}" if key == 'spectral_energy' else f"{fft_data[key]:.4f}"
                                )
                
                # Compression artifacts
                if 'compression_artifacts' in freq_data:
                    st.subheader("üóúÔ∏è Compression Artifacts")
                    comp_data = freq_data['compression_artifacts']
                    
                    if 'blocking_artifacts' in comp_data:
                        blocking = comp_data['blocking_artifacts']
                        st.metric("Blocking Score", f"{blocking.get('blocking_score', 0):.4f}")
                    
                    if 'compression_ratio_estimate' in comp_data:
                        st.metric("Estimated Quality", f"{comp_data['compression_ratio_estimate']:.1f}%")
        else:
            st.info("Frequency analysis not performed.")
    
    def render_temporal_analysis_tab(self, results: Dict):
        """Render temporal analysis results for videos."""
        detections = results.get('detections', {})
        
        if 'temporal_analysis' in detections:
            temporal_data = detections['temporal_analysis']
            
            if 'error' in temporal_data:
                st.error(f"Temporal Analysis Error: {temporal_data['error']}")
            else:
                # Motion analysis
                if 'motion_smoothness' in temporal_data:
                    st.subheader("üé¨ Motion Analysis")
                    motion_data = temporal_data['motion_smoothness']
                    
                    if 'motion_smoothness_score' in motion_data:
                        st.metric("Motion Smoothness", f"{motion_data['motion_smoothness_score']:.3f}")
                
                # Optical flow
                if 'optical_flow' in temporal_data:
                    st.subheader("üåä Optical Flow Analysis")
                    flow_data = temporal_data['optical_flow']
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if 'flow_consistency' in flow_data:
                            st.metric("Flow Consistency", f"{flow_data['flow_consistency']:.3f}")
                    
                    with col2:
                        if 'anomalous_motion' in flow_data:
                            st.metric("Anomalous Motion Events", flow_data['anomalous_motion'])
                    
                    with col3:
                        if 'magnitude_variance' in flow_data:
                            st.metric("Motion Variance", f"{flow_data['magnitude_variance']:.3f}")
                
                # Frame differences
                if 'frame_differences' in temporal_data:
                    st.subheader("üìê Frame Difference Analysis")
                    diff_data = temporal_data['frame_differences']
                    
                    if 'difference_consistency' in diff_data:
                        st.metric("Difference Consistency", f"{diff_data['difference_consistency']:.3f}")
                
                # Show temporal consistency visualization
                if temporal_data and not temporal_data.get('error'):
                    st.subheader("üìä Temporal Consistency Visualization")
                    try:
                        temporal_fig = self.timeline_visualizer.create_temporal_consistency_plot(temporal_data)
                        st.plotly_chart(temporal_fig, use_container_width=True)
                    except Exception as e:
                        st.warning(f"Could not generate temporal consistency plot: {str(e)}")
        else:
            st.info("Temporal analysis not performed.")
    
    def render_timeline_analysis_tab(self, results: Dict):
        """Render timeline analysis with frame-by-frame visualization."""
        frame_analysis = results.get('frame_analysis', [])
        video_metadata = results.get('video_metadata', {})
        
        if not frame_analysis:
            st.info("No frame-by-frame analysis available.")
            return
        
        st.subheader("üìà Detection Timeline")
        st.write("Interactive timeline showing deep fake detection confidence across video frames.")
        
        try:
            # Create detection timeline
            timeline_fig = self.timeline_visualizer.create_detection_timeline(frame_analysis, video_metadata)
            st.plotly_chart(timeline_fig, use_container_width=True)
            
            # Create confidence heatmap
            st.subheader("üî• Detection Confidence Heatmap")
            heatmap_fig = self.timeline_visualizer.create_confidence_heatmap(frame_analysis, video_metadata)
            st.plotly_chart(heatmap_fig, use_container_width=True)
            
            # Export timeline data option
            st.subheader("üìä Export Timeline Data")
            if st.button("Export Timeline Data as CSV"):
                try:
                    timeline_df = self.timeline_visualizer.export_timeline_data(frame_analysis, video_metadata)
                    csv = timeline_df.to_csv(index=False)
                    st.download_button(
                        label="Download CSV",
                        data=csv,
                        file_name="deepfake_timeline_analysis.csv",
                        mime="text/csv"
                    )
                    st.success("Timeline data prepared for download!")
                except Exception as e:
                    st.error(f"Error exporting data: {str(e)}")
            
            # Frame-by-frame detailed analysis
            st.subheader("üé¨ Frame-by-Frame Analysis")
            
            # Frame-by-frame analysis (simplified view)
            try:
                frame_fig = self.timeline_visualizer.create_frame_by_frame_analysis(frame_analysis, [])
                st.plotly_chart(frame_fig, use_container_width=True)
            except Exception as e:
                st.warning(f"Could not generate frame-by-frame visualization: {str(e)}")
            
            # Analysis summary
            st.subheader("üìã Analysis Summary")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                avg_confidence = np.mean([
                    self.timeline_visualizer._get_overall_confidence(result) 
                    for result in frame_analysis
                ])
                st.metric("Average Confidence", f"{avg_confidence:.1%}")
            
            with col2:
                high_conf_frames = sum(1 for result in frame_analysis 
                                     if self.timeline_visualizer._get_overall_confidence(result) > 0.7)
                st.metric("High Confidence Frames", f"{high_conf_frames}/{len(frame_analysis)}")
            
            with col3:
                model_agreement = np.mean([
                    self.timeline_visualizer._calculate_model_agreement(result)
                    for result in frame_analysis
                ])
                st.metric("Model Agreement", f"{model_agreement:.1%}")
                
        except Exception as e:
            st.error(f"Error generating timeline analysis: {str(e)}")
            st.info("Timeline analysis requires valid frame analysis data.")
    
    def render_metadata_tab(self, results: Dict):
        """Render metadata information."""
        metadata = results.get('metadata', {})
        properties = results.get('properties', {})
        
        if metadata:
            st.subheader("üìã Image Metadata")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Basic Information:**")
                for key in ['format', 'size', 'mode']:
                    if key in metadata and metadata[key]:
                        st.write(f"- **{key.title()}:** {metadata[key]}")
                
                if 'creation_software' in metadata and metadata['creation_software']:
                    st.write(f"- **Software:** {metadata['creation_software']}")
            
            with col2:
                st.write("**Camera Information:**")
                camera_info = metadata.get('camera_info', {})
                if camera_info:
                    for key, value in camera_info.items():
                        st.write(f"- **{key.title()}:** {value}")
                else:
                    st.write("No camera information available")
        
        if properties:
            st.subheader("üîç Image Properties")
            
            # Quality metrics
            quality_metrics = properties.get('quality_metrics', {})
            if quality_metrics:
                st.write("**Quality Metrics:**")
                metrics_cols = st.columns(4)
                
                metric_names = ['sharpness', 'contrast', 'brightness', 'edge_density']
                for i, metric in enumerate(metric_names):
                    if metric in quality_metrics:
                        with metrics_cols[i]:
                            st.metric(
                                metric.replace('_', ' ').title(),
                                f"{quality_metrics[metric]:.2f}"
                            )
    
    def render_video_info_tab(self, results: Dict):
        """Render video information."""
        video_metadata = results.get('video_metadata', {})
        
        if video_metadata:
            st.subheader("üé¨ Video Information")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Basic Properties:**")
                for key in ['fps', 'frame_count', 'duration']:
                    if key in video_metadata:
                        value = video_metadata[key]
                        if key == 'duration':
                            st.write(f"- **Duration:** {value:.2f} seconds")
                        elif key == 'fps':
                            st.write(f"- **Frame Rate:** {value:.2f} fps")
                        else:
                            st.write(f"- **{key.replace('_', ' ').title()}:** {value}")
            
            with col2:
                st.write("**Resolution:**")
                if 'width' in video_metadata and 'height' in video_metadata:
                    st.write(f"- **Dimensions:** {video_metadata['width']} √ó {video_metadata['height']}")
                
                if 'codec' in video_metadata:
                    st.write(f"- **Codec:** {video_metadata['codec']}")
        
        # Frame analysis summary
        frame_analysis = results.get('frame_analysis', [])
        if frame_analysis:
            st.subheader("üìä Frame Analysis Summary")
            
            # Create summary statistics
            meso_scores = []
            xception_scores = []
            
            for frame_result in frame_analysis:
                if 'mesonet' in frame_result and 'probability' in frame_result['mesonet']:
                    meso_scores.append(frame_result['mesonet']['probability'])
                
                if 'xception' in frame_result and 'probability' in frame_result['xception']:
                    xception_scores.append(frame_result['xception']['probability'])
            
            if meso_scores or xception_scores:
                fig = make_subplots(
                    rows=1, cols=2,
                    subplot_titles=('MesoNet Scores', 'Xception Scores')
                )
                
                if meso_scores:
                    fig.add_trace(
                        go.Scatter(
                            y=meso_scores,
                            mode='lines+markers',
                            name='MesoNet',
                            line=dict(color='blue')
                        ),
                        row=1, col=1
                    )
                
                if xception_scores:
                    fig.add_trace(
                        go.Scatter(
                            y=xception_scores,
                            mode='lines+markers',
                            name='Xception',
                            line=dict(color='red')
                        ),
                        row=1, col=2
                    )
                
                fig.update_layout(
                    title="Detection Scores Across Analyzed Frames",
                    showlegend=False
                )
                
                st.plotly_chart(fig, use_container_width=True)
    
    def run(self):
        """Main application runner."""
        self.render_header()
        
        # Render sidebar and get settings
        settings = self.render_sidebar()
        
        # Main content area
        st.markdown("### üì§ Upload Media for Analysis")
        
        # File upload
        uploaded_file = st.file_uploader(
            "Choose an image or video file",
            type=['jpg', 'jpeg', 'png', 'bmp', 'tiff', 'mp4', 'avi', 'mov', 'mkv', 'webm'],
            help="Supported formats: Images (JPG, PNG, BMP, TIFF) and Videos (MP4, AVI, MOV, MKV, WEBM)"
        )
        
        if uploaded_file is not None:
            file_type = "image" if uploaded_file.type.startswith('image/') else "video"
            
            st.success(f"‚úÖ Uploaded: {uploaded_file.name} ({file_type})")
            
            # Show file info
            file_size_mb = len(uploaded_file.getvalue()) / (1024 * 1024)
            st.info(f"üìÅ File size: {file_size_mb:.2f} MB")
            
            # Process button
            if st.button("üîç Analyze for Deep Fakes", type="primary"):
                with st.spinner(f"Analyzing {file_type}... This may take a few moments."):
                    start_time = time.time()
                    
                    if file_type == "image":
                        results = self.process_image(uploaded_file, settings)
                    else:
                        results = self.process_video(uploaded_file, settings)
                    
                    end_time = time.time()
                    processing_time = end_time - start_time
                
                st.success(f"‚úÖ Analysis completed in {processing_time:.2f} seconds")
                
                # Render results
                self.render_results(results, file_type)
        
        else:
            # Show information about the system
            st.markdown("### ‚ÑπÔ∏è About This System")
            
            st.markdown("""
            This production-grade deep fake detection system uses multiple AI models and analysis techniques:
            
            **ü§ñ AI Models:**
            - **MesoNet:** Specialized CNN for detecting face manipulation artifacts
            - **Xception:** Advanced deep learning model fine-tuned for deep fake detection
            
            **üîç Analysis Methods:**
            - **Facial Geometry:** Detects inconsistencies in facial landmarks and proportions
            - **Temporal Analysis:** Analyzes frame-to-frame consistency in videos
            - **Frequency Domain:** Examines compression artifacts and spectral anomalies
            - **Multi-modal Fusion:** Combines multiple detection methods for robust results
            
            **üìä Features:**
            - Real-time processing with confidence scoring
            - Detailed technical breakdown of detection factors
            - Support for multiple image and video formats
            - Metadata extraction and analysis
            """)
            
            # Show sample statistics or system status
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Supported Formats", "9")
            
            with col2:
                st.metric("AI Models", "4")
            
            with col3:
                st.metric("Analysis Methods", "6")
            
            with col4:
                st.metric("Detection Accuracy", "95%+")

def main():
    """Main function to run the Streamlit app."""
    app = DeepFakeDetectionApp()
    app.run()

if __name__ == "__main__":
    main()
